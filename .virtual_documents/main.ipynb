!pip install mediapipe opencv-python


import mediapipe as mp
import cv2
import numpy as np
import uuid
import os
from IPython.display import Image


mp_drawing = mp.solutions.drawing_utils
#mp_hands = mp.solutions.hands
mp_holistic = mp.solutions.holistic


Image(url="https://i.imgur.com/qpRACer.png")


mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)



#mp_drawing.draw_landmarks??


# import cv2
# import mediapipe as mp

# # Initialize Mediapipe FaceMesh and Hands
# mp_face_mesh = mp.solutions.face_mesh
# mp_hands = mp.solutions.hands

# face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)


# # Load the webcam video feed
# cap = cv2.VideoCapture(0)

# # Define colors for visualizing face mesh and hands
# face_colors = {
#     'LIPS': (0, 0, 255),  # Red
#     'LEFT_EYE': (0, 255, 0),  # Green
#     'RIGHT_EYE': (255, 255, 0),  # Cyan
#     'FACE_OVAL': (128, 0, 128),  # Purple
#     'NOSE': (255, 0, 255),  # Magenta
# }

# hand_color = (0, 255, 255)  # Yellow

# # Loop through webcam frames
# while cap.isOpened():
#     success, frame = cap.read()
#     if not success:
#         break

#     # Flip and convert the frame for Mediapipe processing
#     frame = cv2.flip(frame, 1)
#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

#     # Process face mesh and hands
#     face_results = face_mesh.process(rgb_frame)
#     hand_results = hands.process(rgb_frame)

#     # Draw face mesh
#     if face_results.multi_face_landmarks:
#         for face_landmarks in face_results.multi_face_landmarks:
#             for name, connections in [
#                 ('LIPS', FACEMESH_LIPS),
#                 ('LEFT_EYE', FACEMESH_LEFT_EYE),
#                 ('RIGHT_EYE', FACEMESH_RIGHT_EYE),
#                 ('FACE_OVAL', FACEMESH_FACE_OVAL),
#                 ('NOSE', FACEMESH_NOSE),
#             ]:
#                 for connection in connections:
#                     start_idx, end_idx = connection
#                     start_point = face_landmarks.landmark[start_idx]
#                     end_point = face_landmarks.landmark[end_idx]

#                     # Convert normalized coordinates to pixel coordinates
#                     h, w, _ = frame.shape
#                     start_coords = (int(start_point.x * w), int(start_point.y * h))
#                     end_coords = (int(end_point.x * w), int(end_point.y * h))

#                     # Draw the line
#                     cv2.line(frame, start_coords, end_coords, face_colors[name], 2)

#     # 2. Right hand landmarks
#         if results.right_hand_landmarks:
#             mp_drawing.draw_landmarks(
#                 image,
#                 results.right_hand_landmarks,
#                 mp_holistic.HAND_CONNECTIONS,
#                 mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),
#                 mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)
#             )

#             # Extract right hand fingertips
#             fingertips = {4: "Thumb", 8: "Index", 12: "Middle", 16: "Ring", 20: "Pinky"}
#             for idx, name in fingertips.items():
#                 landmark = results.right_hand_landmarks.landmark[idx]
#                 x, y = int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])
#                 cv2.circle(image, (x, y), 5, (0, 255, 0), -1)
#                 cv2.putText(image, name, (x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)

#         # 3. Left hand landmarks
#         if results.left_hand_landmarks:
#             mp_drawing.draw_landmarks(
#                 image,
#                 results.left_hand_landmarks,
#                 mp_holistic.HAND_CONNECTIONS,
#                 mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),
#                 mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)
#             )

#             # Extract left hand fingertips
#             fingertips = {4: "Thumb", 8: "Index", 12: "Middle", 16: "Ring", 20: "Pinky"}
#             for idx, name in fingertips.items():
#                 landmark = results.left_hand_landmarks.landmark[idx]
#                 x, y = int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])
#                 cv2.circle(image, (x, y), 5, (0, 255, 0), -1)
#                 cv2.putText(image, name, (x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)

#     # Show the frame
#     cv2.imshow('Hands and Face Mesh', frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break

# # Release resources
# cap.release()
# cv2.destroyAllWindows()



import math
# Function to calculate Euclidean distance
def calculate_distance(point1, point2):
    return math.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)



import cv2
import mediapipe as mp

# Initialize MediaPipe Holistic, FaceMesh, Drawing utilities
mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils
mp_face_mesh = mp.solutions.face_mesh
mp_hands = mp.solutions.hands

# Define MediaPipe FaceMesh connections
FACEMESH_LIPS = frozenset([(61, 146), (146, 91), (91, 181), (181, 84), (84, 17),
                           (17, 314), (314, 405), (405, 321), (321, 375),
                           (375, 291), (61, 185), (185, 40), (40, 39), (39, 37),
                           (37, 0), (0, 267),
                           (267, 269), (269, 270), (270, 409), (409, 291),
                           (78, 95), (95, 88), (88, 178), (178, 87), (87, 14),
                           (14, 317), (317, 402), (402, 318), (318, 324),
                           (324, 308), (78, 191), (191, 80), (80, 81), (81, 82),
                           (82, 13), (13, 312), (312, 311), (311, 310),
                           (310, 415), (415, 308)])

FACEMESH_LEFT_EYE = frozenset([(263, 249), (249, 390), (390, 373), (373, 374),
                               (374, 380), (380, 381), (381, 382), (382, 362),
                               (263, 466), (466, 388), (388, 387), (387, 386),
                               (386, 385), (385, 384), (384, 398), (398, 362)])

FACEMESH_RIGHT_EYE = frozenset([(33, 7), (7, 163), (163, 144), (144, 145),
                                (145, 153), (153, 154), (154, 155), (155, 133),
                                (33, 246), (246, 161), (161, 160), (160, 159),
                                (159, 158), (158, 157), (157, 173), (173, 133)])

FACEMESH_FACE_OVAL = frozenset([(10, 338), (338, 297), (297, 332), (332, 284),
                                (284, 251), (251, 389), (389, 356), (356, 454),
                                (454, 323), (323, 361), (361, 288), (288, 397),
                                (397, 365), (365, 379), (379, 378), (378, 400),
                                (400, 377), (377, 152), (152, 148), (148, 176),
                                (176, 149), (149, 150), (150, 136), (136, 172),
                                (172, 58), (58, 132), (132, 93), (93, 234),
                                (234, 127), (127, 162), (162, 21), (21, 54),
                                (54, 103), (103, 67), (67, 109), (109, 10)])

FACEMESH_NOSE = frozenset([(168, 6), (6, 197), (197, 195), (195, 5),
                           (5, 4), (4, 1), (1, 19), (19, 94), (94, 2), (98, 97),
                           (97, 2), (2, 326), (326, 327), (327, 294),
                           (294, 278), (278, 344), (344, 440), (440, 275),
                           (275, 4), (4, 45), (45, 220), (220, 115), (115, 48),
                           (48, 64), (64, 98)])

# Threshold for fingertip proximity to facial features
THRESHOLD_DISTANCE = 25 #(in pixels)


# Colors for different face features
face_colors = {
    'LIPS': (0, 0, 255),  # Red
    'LEFT_EYE': (255, 255, 0),  # Cyan
    'RIGHT_EYE': (255, 255, 0),  # Cyan
    'FACE_OVAL': (128, 0, 128),  # Purple
    'NOSE': (0, 255, 0),  # Green
}

# Initialize MediaPipe FaceMesh and Hands
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Unable to access the camera.")
    exit()

with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("Error: Unable to read from the camera.")
            break

        # Recolor Feed
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # Flip horizontal
        image = cv2.flip(image, 1)
        # Make Detections
        results = holistic.process(image)
        hand_results = hands.process(image)

        # Recolor image back to BGR for rendering
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        # Draw custom face mesh
        if results.face_landmarks:
            for name, connections in [
                ('LIPS', FACEMESH_LIPS),
                ('LEFT_EYE', FACEMESH_LEFT_EYE), #SWAPPED DUE TO FLIPPED CAMERA
                ('RIGHT_EYE', FACEMESH_RIGHT_EYE),
                ('FACE_OVAL', FACEMESH_FACE_OVAL),
                ('NOSE', FACEMESH_NOSE),
            ]:
                for connection in connections:
                    start_idx, end_idx = connection
                    start_point = results.face_landmarks.landmark[start_idx]
                    end_point = results.face_landmarks.landmark[end_idx]

                    # Convert normalized coordinates to pixel coordinates
                    h, w, _ = frame.shape
                    start_coords = (int(start_point.x * w), int(start_point.y * h))
                    end_coords = (int(end_point.x * w), int(end_point.y * h))

                    # Draw the line with custom color
                    #cv2.line(image, start_coords, end_coords, face_colors[name], 2)

        # Check for right hand landmarks
        if hand_results.multi_hand_landmarks:
            for hand_landmarks in hand_results.multi_hand_landmarks:
                # Draw hand landmarks
                mp_drawing.draw_landmarks(
                    image,
                    hand_landmarks,
                    mp_holistic.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),
                    mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)
                )

                # Extract hand fingertips
                fingertips = {4: "Thumb", 8: "Index", 12: "Middle", 16: "Ring", 20: "Pinky"}
                for idx, name in fingertips.items():
                    landmark = hand_landmarks.landmark[idx]
                    x, y = int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])
                    cv2.circle(image, (x, y), 5, (0, 255, 0), -1)
                    cv2.putText(image, name, (x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)
                
                    # Check for proximity to facial features
                    if results.face_landmarks:
                        for name, connections in [
                            ('LEFT_EYE', FACEMESH_LEFT_EYE),
                            ('RIGHT_EYE', FACEMESH_RIGHT_EYE),
                            ('LIPS', FACEMESH_LIPS),
                            ('NOSE', FACEMESH_NOSE),
                            ('FACE_OVAL', FACEMESH_FACE_OVAL)
                        ]:
                            for connection in connections:
                                start_idx, end_idx = connection
                                start_point = results.face_landmarks.landmark[start_idx]
                                end_point = results.face_landmarks.landmark[end_idx]
                
                                # Convert to pixel coordinates
                                h, w, _ = frame.shape
                                start_coords = (int(start_point.x * w), int(start_point.y * h))
                                end_coords = (int(end_point.x * w), int(end_point.y * h))
                
                                # Calculate the distance to the fingertip
                                fingertip_coords = (x, y)
                                distance_to_start = calculate_distance(fingertip_coords, start_coords)
                                distance_to_end = calculate_distance(fingertip_coords, end_coords)
                
                                # If the fingertip is close to the face feature, show an alert
                                if distance_to_start < THRESHOLD_DISTANCE or distance_to_end < THRESHOLD_DISTANCE:
                                    #alert_count += 1
                                    if name == "LIPS":
                                        cv2.putText(image, 'Biting nails', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)
                                    elif name == "LEFT_EYE":
                                        cv2.putText(image, 'Rubbing Right Eye', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)
                                    elif name == "RIGHT_EYE":
                                        cv2.putText(image, 'Rubbing Left Eye', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)
                                    elif name == "NOSE":
                                        cv2.putText(image, 'Booger Alert!', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
                                    elif name == "FACE_OVAL":
                                        cv2.putText(image, 'Potential skin picking', (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (128, 0, 128), 2, cv2.LINE_AA)

                                # After checking all features, check if multiple alerts were detected
                                # if alert_count > 1:
                                #     cv2.putText(image, 'MULTIPLE ALERTS DETECTED', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)
        # Display the resulting frame
        cv2.imshow('Raw Webcam Feed', image)

        if cv2.waitKey(10) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyAllWindows()










